# -*- coding: utf-8 -*-
"""Prueba Claro-Insurance.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nWO8tbrL0nRDvKQXc3_Kn-O70ps8fczK

# PRUEBA DE SELECCIÓN - DATA SCIENCE – Claro Insurance

**Andrés Amaya Chaves**

(A) Se realiza importación de los paquetes necesarios para desarrollar el código.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import datetime as dt
from scipy import stats
import seaborn as sns
import warnings
import statistics as stats
import itertools as it
from google.colab import drive 

from scipy import stats as sts
from sklearn.preprocessing import StandardScaler
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans
import plotly.offline as pyoff
import plotly.graph_objs as go
from scipy.spatial.distance import cdist
import warnings

warnings.filterwarnings("ignore")

"""(B) Se leen los datos desde un repositorio personal en GitHub, el cual permanecerá público únicamente mientras se realiza la calificación de la presente prueba para garantizar el acceso desde este notebook. Usando esta opción no se requiere ninguna autenticación al ejecutar el Notebook."""

Cliente = pd.read_csv('https://raw.githubusercontent.com/andresamayachaves/PruebaDataScience/main/Cliente.csv', encoding= 'unicode_escape')
DetalleOrden = pd.read_csv('https://raw.githubusercontent.com/andresamayachaves/PruebaDataScience/main/DetalleOrden.csv', encoding= 'unicode_escape') 
Orden = pd.read_csv('https://raw.githubusercontent.com/andresamayachaves/PruebaDataScience/main/Orden.csv', encoding= 'unicode_escape')     
Producto = pd.read_csv('https://raw.githubusercontent.com/andresamayachaves/PruebaDataScience/main/Producto.csv', encoding= 'unicode_escape')

# Exploración de las 5 primeras líneas de cada tabla & su longitud, para dar un vistazo a la información.
Cliente.head(5)

DetalleOrden.head(5)

Orden.head(5)

Producto.head(5)

({'LenOrden':len(Orden),'LenCliente':len(Cliente),'LenDetalleOrden':len(DetalleOrden),'LenProducto':len(Producto)})

"""# (1) Se procede al análisis descriptivo

(1A) Productos más vendidos. Productos menos vendidos. (En cada caso se ecploró hasta el 3er valor distinto)
"""

# Exploración de la proporción de valores vacíos en cada una de las tablas
pd.set_option('display.max_columns', None)
print(Orden.isnull().mean())
print(Cliente.isnull().mean())
print(DetalleOrden.isnull().mean())
print(Producto.isnull().mean())

CantidadProducto = DetalleOrden.groupby('PRODUCTCODE').agg({'QUANTITYORDERED': lambda x:x.sum()}).sort_values(by = ['PRODUCTCODE'], ascending = False)
CantProd = pd.merge(Producto, CantidadProducto, how = "left", on = "PRODUCTCODE").sort_values(by = 'QUANTITYORDERED', ascending = False)

CantProd.rename(columns={'ORDERNUMBER':'SOLD_ITEMS_QUANTITY'}, inplace=True)
CantProd.head(10)

CantProd.tail(10)

print('---------------------------------------')
print("De los ", len(Producto['PRODUCTCODE']), "productos disponibles, \
aquel con la mayor cantidad de unidades vendidas corresponde al siguiente:")
print(CantProd.head(1))

print('---------------------------------------')
print("De los ", len(Producto['PRODUCTCODE']), "productos disponibles, \
aquel con la menor cantidad de unidades vendidas corresponde al siguiente:")
print(CantProd.tail(1))
print('---------------------------------------')

"""(1B) Histograma volumen de compras por cada cliente, cantidad total ordenada durante todo el periodo de estudio. Media, mediana, desviación estándar, varianza, moda (μ, median, σ, σ^2, mode)"""

q = DetalleOrden.groupby('ID_Cliente').agg('count')   # Cantidad de compras efectuada por cada cliente
q = q['QUANTITYORDERED']

mu       = round(stats.mean(q),2)
median   = round(stats.median(q),2)
sigmma   = round(stats.stdev(q),2)
variance = round(stats.variance(q),2)
mode     = round(stats.mode(q),2)

print({'mu':mu,'Mediana':median, 'Sigma':sigmma,'Varianza':variance, 'Moda':mode})

hist, _ = np.histogram(q, range=(0, q.max()), bins=q.max() + 1) # Construye el Histograma

# Configura la visualización del histograma
n, bins, patches = plt.hist(x=q, bins='auto', color='#0504aa',
                            alpha=0.7, rwidth=0.85)
plt.rcParams["figure.figsize"] = (9,7)
plt.grid(axis='y', alpha=0.75)
plt.xlabel('Volumen Individual de Compras')
plt.ylabel('Frequencia')
plt.title('Histograma Volumen Compras por Cada Cliente')
plt.text(155, 17.5, r'$media=%s, Mediana=%s$'%(mu,median))
plt.text(155, 15.5, r'$Sigmma=%s$'%(sigmma))
plt.text(155, 13.5, r'$Varianza=%s$'%(variance))
plt.text(155, 11.5, r'$Moda=%s$'%(mode))
plt.text(155, 9, '["Cantidad de Compras"]')

maxfreq = n.max()
plt.ylim(ymax=np.ceil(maxfreq / 10) * 8 if maxfreq % 10 else maxfreq + 10)

"""(1C) Identificación de los clientes con mayor volumen de compras. Se observan datos bastante excéntricos por encima de 150 compras, entonces se filtra para cantidades superiores a este valor."""

qq = pd.DataFrame(q)
qFil = qq[qq['QUANTITYORDERED']>150]

ClientesSup = pd.merge(qFil, Cliente, how = "left", on = "ID_Cliente")
ClientesSup

"""(1D) Distribución del monto de ventas en el tiempo. Mes con máximo en ventas, mes con mínimo en ventas. Total acumulado de ventas.

"""

OrdenCompleta = pd.merge(DetalleOrden, Orden, how = "left", on = "ORDERNUMBER")
OrdenCompleta['ORDERDATE'] = pd.to_datetime(OrdenCompleta['ORDERDATE'])
OrdenGrupo = OrdenCompleta.groupby('ORDERDATE').agg({'SALES':lambda x: x.sum()}).sort_values(by="ORDERDATE")

OrdenGrupo = pd.DataFrame({'ORDERDATE': OrdenGrupo.index, 'SALES': OrdenGrupo['SALES']})
OrdenGrupo.reset_index(drop=True)

pd.set_option('max_rows', 30)

VentaMax, VentaMin, VentaMedia = max(OrdenGrupo['SALES']),min((OrdenGrupo['SALES'])), round(OrdenGrupo['SALES'].mean(),2)
TotalVentas = "${:,.2f}".format(round(sum(OrdenCompleta['SALES']),2))

MaxDate = OrdenGrupo[OrdenGrupo['SALES']==VentaMax]['ORDERDATE']
MinDate = OrdenGrupo[OrdenGrupo['SALES']==VentaMin]['ORDERDATE']

MaxDate = pd.to_datetime(MaxDate)
MinDate = pd.to_datetime(MinDate)

MaxDate = MaxDate.dt.date.values[0]       # + "-" + str(MaxDate.dt.month) +str(MaxDate.dt.year) #[-48:-36])  # , '%-d/%-m/%-y') ##[6:16]
MinDate = MinDate.dt.date.values[0]         #.dt.strftime('%/d/%/m/%y %I:%M')#[7:17]    #RFEVISAR FORMATO!! ///////////////

plt.bar(OrdenGrupo['ORDERDATE'], OrdenGrupo['SALES'], )
plt.rcParams["figure.figsize"] = (5,8)
plt.grid(axis='y', alpha=0.75)
plt.xlabel('Tiempo [Fecha de Venta]', fontsize = 19)
plt.ylabel('Monto de Ventas', fontsize = 19)
plt.title('MONTO DE VENTAS VS. TIEMPO', fontsize = 23)
plt.text(dt.datetime(2004,1,1), 135000, r'Máximo=%s @ %s'%(VentaMax,MaxDate), fontsize = 14.5)
plt.text(dt.datetime(2004,1,1), 125000, r'Mínimo=%s @ %s'%(VentaMin,MinDate), fontsize = 14.5)
plt.text(dt.datetime(2004,1,1), 115000, r'Media=%s'%(VentaMedia), fontsize = 14.5)
plt.text(dt.datetime(2004,1,1), 105000, r'Acum. Ventas = %s'%(TotalVentas), fontsize = 14.5)
plt.xticks(rotation=45, fontsize=14)
plt.tick_params(axis='y', labelsize=16)
plt.tick_params(axis='x', labelsize=16)

#q = DetalleOrden.groupby('ID_Cliente').agg('count') 
#OrdenCompleta['YEAR_ID'] = OrdenCompleta['YEAR_ID'].apply(str)
#OrdenCompleta['MONTH_ID'].apply(str)

OrdenCompleta['YearMonth'] =  OrdenCompleta['YEAR_ID'].apply(str) + "-" + OrdenCompleta['MONTH_ID'].apply(str)
#print(OrdenCompleta.head(10))
OrdenCompleta['YearMonth'] =  pd.to_datetime(OrdenCompleta['YearMonth'])
SalesMonth = OrdenCompleta.groupby('YearMonth').agg({'SALES': lambda x: x.sum()}).sort_values(by = 'YearMonth', ascending = True)
SalesMonth.head(5)

YearM = SalesMonth.index.values
YearM = pd.DataFrame({"YearMonth":YearM})

y_pos = np.arange(len(SalesMonth))
k = YearM['YearMonth']
L = []
for i in YearM['YearMonth']: L.append(str(i)[:7])

x_pos= np.arange(len(SalesMonth))

plt.bar(x_pos, SalesMonth['SALES'], color='#0504aa')
plt.rcParams["figure.figsize"] = (13,9)
plt.xticks(y_pos, L, rotation=45, fontsize=14)
plt.grid(axis='y', alpha=0.75)
plt.xlabel('Tiempo [Fecha de Venta]', fontsize=17)
plt.ylabel('Monto de Ventas [*10^6]',fontsize=17)
plt.title('MONTO DE VENTAS POR MES', fontsize=23)
plt.tick_params(axis='y', labelsize=16)
plt.text(1,1060000, r'TOTAL VENTAS PERIODO DE ESTUDIO = %s'%(TotalVentas), fontsize = 14)     #dt.datetime(2003,1,1),
plt.show()

"""(1E) Distribución de los clientes según ciudad. Ciudad donde se ubica la mayor cantidad de clientes."""

# Commented out IPython magic to ensure Python compatibility.
z = Cliente.groupby('CITY').agg('count').sort_values(by="ID_Cliente", ascending=False)
#print(z)
z = z['ID_Cliente']
ZZ = z.index.values
ZZ1 = ZZ[z>1] 
#print(ZZ)
#print(len(ZZ))
#print(ZZ1)

plt.rcdefaults()
fig, ax = plt.subplots()
y_pos = np.arange(len(ZZ1))

ax.barh(y_pos,z.iloc[:len(ZZ1)], align='center', color='#0504aa')
ax.set_yticks(y_pos)
ax.set_yticklabels(ZZ1)
ax.invert_yaxis()  # labels read top-to-bottom
ax.set_xlabel('Cantidad Clientes en la Ciudad')
ax.set_title('Distribución de Clientes por Ciudad')

CiudadMasClientes = ZZ1[0]
CantMasClientes = z[0]

print(r'%s es la ciudad con mayor cantidad de clientes en el periodo de estudio. \
Allí se ubican %s clientes.'%(CiudadMasClientes,CantMasClientes))

print(r'Las ciudades donde se ubican al menos 2 clientes son %s y se muestran en la figura; existen al menos 2 \
clientes dentro de estas ciudades. Las otras %s ciudades registran un solo cliente cada una.'\
# %(len(ZZ1), len(z)-len(ZZ1)))

"""(1F) Distribución de los clientes según estado. Estado donde se ubica la mayor cantidad de clientes."""

# Commented out IPython magic to ensure Python compatibility.
s = Cliente.groupby('STATE').agg('count').sort_values(by="ID_Cliente", ascending=False)
s = s['ID_Cliente']
SS = s.index.values
SS1 = SS[s>1] 

plt.rcdefaults()
fig, ax = plt.subplots()
y_pos = np.arange(len(SS1))

ax.barh(y_pos,s.iloc[:len(SS1)], align='center',  color='#0504aa')
ax.set_yticks(y_pos)
ax.set_yticklabels(SS1)
ax.invert_yaxis()  # labels read top-to-bottom
ax.set_xlabel('Cantidad Clientes en el estado')
ax.set_title('Distribución de Clientes por estado')

EstadoMasClientes = SS1[0]
CantidadEstadoClientes = s[0]

print(r'%s es el estado con mayor cantidad de clientes en el periodo de estudio. \
Allí se ubican %s clientes.'%(EstadoMasClientes,CantidadEstadoClientes))

print(r'Los estados  donde se ubican al menos 2 clientes son %s y se muestran en la figura; existen al menos 2 \
clientes dentro de estos estados. Los otras %s estados registran un solo cliente cada uno.'\
# %(len(SS1), len(s)-len(SS1)))

def self(x):
  t=[]
  for i in x: t=i
  return t

Lineas = pd.merge(OrdenCompleta, Producto, how = "left", on = "PRODUCTCODE")
Lineas = Lineas.groupby('PRODUCTLINE',as_index=False).agg({'PRODUCTLINE': lambda x: self(x), 
                                                  'PRODUCTCODE': lambda x: self(x), 
                                                  'ORDERNUMBER': lambda x: x.count()})
Lineas = Lineas.sort_values(by='ORDERNUMBER', ascending=False)
Lineas

"""Ver análsis del punto (1) en el informe

# (2) SEGMENTACIÓN RFM

Se usarán las siguientes variables para describir las caracteristicas RFM, en todos los casos se trata de información agregada de acuerdo a cada uno de los clientes:


*   Recency: ORDERDATE. Tiempo desde la última compra hasta la fecha de referencia.
*  Freceuncy: ORDERNUMBER. Cantidad de ordenes generadas en el periodo de estudio.
*  Money: SALES. Cantidad de dinero en compras en el periodo de estudio.

## Puntuación de cada cliente en *Recency, Frecuency, Money*. Histograma de cada combiación de clasificación RFM.
"""

refDate = dt.datetime(2005,5,31)

ODO = Orden.merge(DetalleOrden, on='ORDERNUMBER', how = 'right', indicator = 'TRUE')

h = []
for i in ODO['ORDERDATE']: 
  h.append(pd.to_datetime(i))  
ODO['ORDERDATE'] = h

# Información RFM agregada de acuerdo cada cliente
rfm = ODO.groupby('ID_Cliente', as_index=False).agg({'ORDERDATE': lambda x: (refDate - x.max()).days,  # Recency: tiempo desde la última compra hasta la fecha de referencia.
                                     'ORDERNUMBER': lambda x: len(x), # Frecuency: Cantidad de compras en el periodo de estudio
                                     'SALES': lambda x: x.sum()})    #Money: Cantidad de dinero comprada

rfm.columns = ['ID_Cliente','Recency', 'Frequency', 'Monetary']
rfm.head(5)

rfm['r_percentile'] = rfm['Recency'].rank(pct=True,ascending=False)
rfm['f_percentile'] = rfm['Frequency'].rank(pct=True,ascending=True)
rfm['m_percentile'] = rfm['Monetary'].rank(pct=True,ascending=True)
rfm['r_score'] = pd.qcut(rfm['r_percentile'], 5, labels=range(1,6,1))
rfm['f_score'] = pd.qcut(rfm['f_percentile'], 5, labels=range(1,6,1))
rfm['m_score'] = pd.qcut(rfm['m_percentile'], 5, labels=range(1,6,1))            #REVISAR - REVISAR - REVISAR

rfm['rfm_score'] = rfm['r_score'].astype(str) + rfm['f_score'].astype(str) + rfm['m_score'].astype(str)

rfm.head(5)

"""-----------------"""

q=[0.0, 1/5,2/5,3/5, 4/5,1]
r_quintiles = rfm['Recency'].quantile(q).to_list()
f_quintiles = rfm['Frequency'].quantile(q).to_list()
m_quintiles = rfm['Monetary'].quantile(q).to_list()
quantile_spread = pd.DataFrame(list(zip(r_quintiles, f_quintiles, m_quintiles)), 
                      columns=['Q_Recency','Q_Frequency', 'Q_Monetary'],
                     index = ['min', 'first_part (Q1)','second_part (Q2)','third_part (Q3)', 'forth_part(Q4)','max'])
quantile_spread

ax = rfm['rfm_score'].value_counts().plot(kind='bar', figsize=(15, 5), fontsize=12,  color='#0504aa', width=0.82)
ax.set_xlabel("RFM Score", fontsize=12)
ax.set_ylabel("Count", fontsize=12)
ax.set_title('Histograma Puntuación RFM', fontsize = 23)
plt.show()

ax2 = rfm['rfm_score'].value_counts()
ax2 = pd.DataFrame({'rfm_score':ax2.index,'Count':ax2})
ax2 = ax2.sort_values('rfm_score',ascending=True)

x_pos= np.arange(len(ax2))
col = list([np.repeat('#1fb25f',8)])
col.extend([np.repeat('#0504aa',8)])
col.extend([np.repeat('#1fb25f',8)])
col.extend([np.repeat('#0504aa',8)])
col.extend([np.repeat('#1fb25f',8)])
#col = np.array(col)
w = ['dede']
ax2 = ax2.plot(kind='bar', figsize=(15, 5), fontsize=12,  color=col, width=0.82)
ax2.set_xlabel("RFM Score", fontsize=12)
ax2.set_ylabel("Count", fontsize=12)
ax2.set_title('Histograma Puntuación RFM', fontsize = 23)

plt.show()

"""## Clasificación de los Clientes en 5 categorías"""

print(rfm.head(5))
L = [] 

for j in rfm['rfm_score']:
  if j in ('444', '445', '454', '455', '544', '545', '554', '555'):
    L.append('Potencial')
  
  elif j[0] in ('1','2','3') or j[1] in ('1','2','3') or j[2] in ('1','2','3'): 
    L.append('Perdido')
  
  elif j[2] == '5': 
    L.append('Derrochador')

  elif j[1] in ('4','5'):
    L.append('Leal')

  elif j[0] in ('4','5'):
    L.append('Nuevo')

  else: L.append('Desclasificado')

rfm['Rfm_Segment'] = L
print(rfm.head(100))
rfm = pd.DataFrame(rfm)

segmento = rfm.groupby('Rfm_Segment', as_index=False).count()
segmento = segmento.iloc[:,:2]
ls = pd.DataFrame({'Rfm_Segment': ['Derrochador','Leal','Nuevo'], 'ID_Cliente':[0,0,0]})
segmento = segmento.append(ls)
print(segmento)

ax3 = segmento.plot(kind='bar', figsize=(11, 5), fontsize=12,  color='#0504aa', width=0.82)
ax3.set_xlabel("Segmento RFM", fontsize=12)
ax3.set_ylabel("Count", fontsize=12)
ax3.set_title('Histograma Puntuación RFM', fontsize = 23)
plt.grid(axis='y', alpha=1.5)
plt.xticks(np.arange(len(segmento)),segmento['Rfm_Segment'],fontsize=14)

"""# (3) SEGMENTACIÓN POR CLUSTERING

Se utilizó método kmeans para la segmentaciñon RFM.
"""

# Función para verificar asimetría (skewness)
def check_skew(df_skew, column):
    skew = sts.skew(df_skew[column])
    skewtest = sts.skewtest(df_skew[column])
    plt.title('Distribution of ' + column)
    sns.distplot(df_skew[column], color='#0504aa', bins=35)
    print("{}'s: Skew: {}, : {}".format(column, skew, skewtest))
    return

# Verificación asimetría (skewness) de la recencia (R)
check_skew(rfm, 'Recency')
print('')

# Verificación asimetría (skewness) de la frecuencia (F)
check_skew(rfm, 'Frequency')
print('')

# Verificación asimetría (skewness) del Valor Monetario (M)
check_skew(rfm, 'Monetary')

rfm.iloc[:,0:4]

#Remoción de la asimetría
rfm_log = np.log(rfm.iloc[:,1:4]+0.0001)
plt.figure(figsize=(9, 9))
plt.subplot(3, 1, 1)

check_skew(rfm_log,'Recency')
plt.subplot(3, 1, 2)

check_skew(rfm_log,'Frequency')
plt.subplot(3, 1, 3)

check_skew(rfm_log,'Monetary')
plt.tight_layout()

scaler = StandardScaler()
scaler.fit(rfm_log)
RFM_Table_scaled = scaler.transform(rfm_log)
RFM_Table_scaled = pd.DataFrame(RFM_Table_scaled, columns = rfm_log.columns)
RFM_Table_scaled

"""Se usa el método del codo (Elbow Method) para averiguar qué cantidad de clusters K es óptima segñun los datos."""

distortions = [] 
inertias = [] 
mapping1 = {} 
mapping2 = {} 
K = range(1,10) 
  
for k in K: 
    #Building and fitting the model 
    kmeanModel = KMeans(n_clusters=k).fit(RFM_Table_scaled) 
    kmeanModel.fit(RFM_Table_scaled)     
      
    distortions.append(sum(np.min(cdist(RFM_Table_scaled, kmeanModel.cluster_centers_, 
                      'euclidean'),axis=1)) / RFM_Table_scaled.shape[0]) 
    inertias.append(kmeanModel.inertia_) 
  
    mapping1[k] = sum(np.min(cdist(RFM_Table_scaled, kmeanModel.cluster_centers_, 
                 'euclidean'),axis=1)) / RFM_Table_scaled.shape[0] 
    mapping2[k] = kmeanModel.inertia_

plt.plot(K, inertias, 'bx-')
plt.xlabel('Values of K')
plt.ylabel('Inertia')
plt.title('The Elbow Method Using Inertia')
plt.show()

"""K = 3 parece un valor apropiado, pues allí es donde la gráfica presenta mayor curvatura. Sin embargo, a continuación se ecxploran las gráficas 'aplanadas' que resultan de usar K=3, K=4 y K=5. Estas son gráficas que corresponden a una tridimensionalidad, pero se 'aplanan' para poder ser representadas en 2 dimensiones."""

def kmeans(normalised_df_rfm, clusters_number, original_df_rfm):
    
    kmeans = KMeans(n_clusters = clusters_number, random_state = 1)
    kmeans.fit(normalised_df_rfm)
                                        
    cluster_labels = kmeans.labels_ # Extrae las etiquetas de los clusters
        
    # Crea una etiqueta de cluster in el conjunto de datos original
    df_new = original_df_rfm.assign(Cluster = cluster_labels)
     
    model = TSNE(random_state=1)
    transformed = model.fit_transform(df_new)
    
    # Plot t-SNE
    plt.title('Flattened Graph of {} Clusters'.format(clusters_number))
    sns.scatterplot(x=transformed[:,0], y=transformed[:,1], hue=cluster_labels, style=cluster_labels, palette="Set1")
    
    return df_new

plt.figure(figsize=(10, 10))
plt.subplot(3, 1, 1)
df_rfm_k3 = kmeans(RFM_Table_scaled, 3, rfm_log)
plt.subplot(3, 1, 2)
df_rfm_k4 = kmeans(RFM_Table_scaled, 4, rfm_log)
plt.subplot(3, 1, 3)
df_rfm_k5 = kmeans(RFM_Table_scaled, 5, rfm_log)
plt.tight_layout()

"""Se efectúan los 'gráficos de serpiente' (*snake plots*) correspondientes a cada valor de K (3, 4,5)."""

def snake_plot(normalised_df_rfm, df_rfm_kmeans, df_rfm_original):
    normalised_df_rfm = pd.DataFrame(normalised_df_rfm, 
                                       index=rfm.index, 
                                       columns=rfm.columns)
    normalised_df_rfm['Cluster'] = df_rfm_kmeans['Cluster']
    # Melt data into long format
    df_melt = pd.melt(normalised_df_rfm.reset_index(), 
                        id_vars=['ID_Cliente', 'Cluster'],
                        value_vars=['Recency', 'Frequency', 'Monetary'], 
                        var_name='Metric', 
                        value_name='Value')
    plt.xlabel('Metric')
    plt.ylabel('Value')
    sns.pointplot(data=df_melt, x='Metric', y='Value', hue='Cluster')
    
    return

snake_plot(RFM_Table_scaled, df_rfm_k3, rfm_log)

snake_plot(RFM_Table_scaled, df_rfm_k4, rfm_log)

snake_plot(RFM_Table_scaled, df_rfm_k5, rfm_log)

def rfm_values(df):
    df_new = df.groupby(['Cluster']).agg({
            'Recency': 'mean',
            'Frequency': 'mean',
            'Monetary': ['mean', 'count']
        }).round(0)
    
    return df_new

rfm_values(df_rfm_k3)

rfm_values(df_rfm_k4)

rfm_values(df_rfm_k5)

""" # (4) MODELO DE SISTEMA DE RECOMENDACIÓN """

ClienteOrden = pd.merge(DetalleOrden, Cliente, how = "left", on = "ID_Cliente").sort_values(by = 'ID_Cliente', ascending = True)
pd.set_option('display.max_columns', None)

ClienteOrden = ClienteOrden.sort_values(by = ['ID_Cliente', 'PRODUCTCODE'], ascending = True)

ClienteProducto = ClienteOrden.groupby(['ID_Cliente', 'ORDERNUMBER'], as_index=False).agg({'ID_Cliente': lambda x: self(x), 
                                                                                           'PRODUCTCODE': lambda x: self(x),                                                                                            
                                                                                           'ORDERNUMBER':lambda x: x.count()})

ClienteProducto = ClienteProducto.sort_values(by=['ID_Cliente','ORDERNUMBER'], ascending=[True,False])
ClienteProducto.columns = ['ID_Cliente', 'PRODUCTCODE', 'Quantity_of_Orders']
ClienteProducto.head(5)

"""Ahora, dado que la cantidad de productos no es muy grande, no resulta computacionalmente muy costoso crear un DataFrame que almacene los 3 productos más cercanos hacia arriba en precio, y demás condiciones descritas en el informe.

Primero, se construyeron 7 variables de tipo DataFrame, una por cada línea de producto, en las cuales se ordenaron los productos de cada de acuerdo a su precio en orden ascendente.
"""

RecomProd = pd.merge(OrdenCompleta, Producto, how = "left", on = "PRODUCTCODE")
RecomProd = RecomProd.iloc[:,[15, 6,3]]
RecomProd = RecomProd.groupby('PRODUCTCODE', as_index = False).agg({ 'PRODUCTLINE': lambda x: self(x), 
                                                   'PRODUCTCODE': lambda x: self(x), 
                                                   'PRICEEACH':   lambda x: x.mean()})
RecomProd = RecomProd.sort_values(by=['PRODUCTLINE', 'PRICEEACH'])

RR = RecomProd.groupby('PRODUCTLINE', as_index = False).agg({ 'PRODUCTLINE': lambda x: self(x), 
                                                              'PRODUCTCODE': lambda x: x.count()})
RR.columns = ['PRODUCTLINE', 'QUANTITY_PRODUCTS']
RR

pd.merge(DetalleOrden,Producto, how= 'left',on='PRODUCTCODE').groupby('PRODUCTLINE').agg({'PRODUCTLINE': lambda x: self(x),
                                                                                          'PRICEEACH': lambda x: x.mean()})\
                                                                                          .sort_values(by='PRICEEACH')

import inspect
LL =[]
f0, f1 = 0,0
for i in RR['PRODUCTLINE']:
  f1 = int(RR['QUANTITY_PRODUCTS'][RR['PRODUCTLINE']==i].values) + f0  
  Tabla = pd.DataFrame(RecomProd.iloc[f0:f1,:])
  f0 = f1
  LL.append(Tabla)        # lista de Líneas de producto con cada producto y su precio 

Classic = LL[0]
Motor   = LL[1]
Planes  = LL[2]
Ships   = LL[3]
Trains  = LL[4]
Buses   = LL[5]
Vintage = LL[6]

AA = [[Classic], [Motor], [Planes], [Ships], [Trains],[Buses], [Vintage]]

def recom(LINE, k):
    et1 = pd.DataFrame(LINE.iloc[1:,1], columns = ['PRODUCTCODE']).append({'PRODUCTCODE':LINE.iloc[-2,1]},  ignore_index=True)
    L = pd.concat([LINE.reset_index(drop=True), et1], axis=1)

    et2 = pd.DataFrame(L.iloc[2:,1], columns = ['PRODUCTCODE']).append({'PRODUCTCODE':LINE.iloc[-2,1]},  ignore_index=True)
    et2 = et2.append({'PRODUCTCODE':LINE.iloc[-3,1]},  ignore_index=True)
    L = pd.concat([L.reset_index(drop=True), et2], axis=1)

    et3 = pd.DataFrame(L.iloc[3:,1], columns = ['PRODUCTCODE']).append({'PRODUCTCODE':LINE.iloc[-2,1]},  ignore_index=True)
    et3 = et3.append({'PRODUCTCODE':LINE.iloc[-3,1]},  ignore_index=True)
    if k != 1:
        et3 = et3.append({'PRODUCTCODE':LINE.iloc[-4,1]},  ignore_index=True)
    else: et3 = et3.append({'PRODUCTCODE':Vintage.iloc[-4,1]},  ignore_index=True)
    L = pd.concat([L.reset_index(drop=True), et3], axis=1)
    L.columns= ['PRODUCETLINE', 'PRODUCTCODE','PRICEEACH','ProdRec1','ProdRec2','ProdRec3']

    return L
    

Classic = recom(Classic,0)
Motor  = recom(Motor,0)
Planes = recom(Planes,0)
Ships  = recom(Ships,0) 
Trains = recom(Trains,1)
Buses  = recom(Buses,0) 
Vintage= recom(Vintage,0)

All_LinesRec = Classic.append(Motor, ignore_index=True)\
                    .append(Planes, ignore_index=True)\
                    .append(Ships, ignore_index=True)\
                    .append(Trains, ignore_index=True)\
                    .append(Buses, ignore_index=True)\
                    .append(Vintage, ignore_index=True)

All_LinesRec

CP = ClienteProducto.groupby('ID_Cliente', as_index= False).agg({'ID_Cliente': lambda x: self(x), 
                                                                   'PRODUCTCODE': lambda x: self(x), 
                                                                   'Quantity_of_Orders': lambda x: x.count()})
CP.columns = ['ID_Cliente','PRODCODE', 'CountCodes']

DropList = []
tt = 0
for i in range(len(CP)):
  for j in range(CP['CountCodes'][i]):
      if j>=2:
          DropList.extend([tt+j])
      else: None
  tt = tt+CP['CountCodes'][i]

ClienteProductoMOD = ClienteProducto.reset_index()
ClienteProductoMOD = ClienteProductoMOD.drop(DropList)

ClienteProductoMOD

Recomendaciones = ClienteProducto.groupby('ID_Cliente', as_index= False).agg({'ID_Cliente': lambda x: self(x)})


#Recomendaciones = pd.concat([Recomendaciones.reset_index(drop=True), LineaFav1], axis=1)
DD = pd.merge(ClienteProductoMOD, Producto[['PRODUCTLINE', 'PRODUCTCODE']],  how = "left", on = "PRODUCTCODE")#.sort_values(by = 'ORDERNUMBER', ascending = False)
#print(Recomendaciones)

w = pd.merge(DD, Recomendaciones,  how = "left", on = "ID_Cliente")#.sort_values(by = 'ORDERNUMBER', ascending = False)
w1 = pd.merge(w, All_LinesRec,  how = "left", on = 'PRODUCTCODE')#.sort_values(by = 'ORDERNUMBER', ascending = False)

w1

def selfie(x):
  t=[]
  for i in x: t.append(i)
  return t[0]
#DefRec1=
#DefRec2=
#Defrec3=
w2 = w1.groupby('ID_Cliente', as_index=False).agg({'ProdRec1': lambda x: selfie(x),
                                   'ProdRec2': lambda x: selfie(x)})
print(len(w1))
#Recomendaciones = pd.concat([w1, w2])

w2.columns = ['ID_Cliente','Recomendadcion1','Recomendadcion2']

pd.set_option('max_rows', None)

ClienteProductoLinea = pd.merge(ClienteProducto, Producto, how = "left", on = "PRODUCTCODE")#.sort_values(by = 'ID_Cliente', ascending = True)
ProdLineCount = ClienteProductoLinea.reset_index().groupby('ID_Cliente', as_index= False).agg({'ID_Cliente': lambda x: self(x), 
                                                                   'PRODUCTLINE': lambda x: x.count()})

ClienteProductoLinea = ClienteProductoLinea.reset_index()
ProductoRecomendado3 = []
for i in range(len(w2)):
    if i == len(w2)-1:
      i = i-1
    if ProdLineCount['PRODUCTLINE'][i]>1:
        ProductoRecomendado3.append(w1['ProdRec1'][2*i+1])
    else: 
        ProductoRecomendado3.append(w1['ProdRec1'][2*i])

ProductoRecomendado3 = pd.DataFrame(ProductoRecomendado3, columns=['Recomendacion3'])

RECOMENDACIONES = pd.concat([w2.reset_index(drop=True),ProductoRecomendado3], axis=1)
RECOMENDACIONES

